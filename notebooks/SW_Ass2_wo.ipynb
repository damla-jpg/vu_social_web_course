{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dcMf4aubeMI9"
   },
   "source": [
    "*****************************************************************\n",
    "#  The Social Web: data representation\n",
    "- Instructors: Davide Ceolin, Emma Beauxis-Aussalet.\n",
    "- TAs: Zubaria Inayat, Maxim Sergeev, Zhuofan Mei, Alexander Schmatz, Ling Jin.\n",
    "- Exercises for Hands-on session 2\n",
    "*****************************************************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhts5HMzeMI-"
   },
   "source": [
    "In this session you are going to mine data in various microformats. You will see the differences in what each of the formats can contain and what purpose they serve. We will start by looking at geographical data.\n",
    "\n",
    "Prerequisites:\n",
    "- Python 3.8\n",
    "- Python packages: requests, BeautifulSoup4, HTMLParser, rdflib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "6f-OtFPPeMJA",
    "outputId": "9bcb836f-4204-4fac-d133-99e81a0b2884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from BeautifulSoup4) (2.3.2.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: HTMLParser in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rdflib) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cloudscraper in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.2.71)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cloudscraper) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.9.2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cloudscraper) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.9.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cloudscraper) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.9.2->cloudscraper) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.9.2->cloudscraper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.9.2->cloudscraper) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.9.2->cloudscraper) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# If you're using a virtualenv, make sure it's activated before running\n",
    "# this cell!\n",
    "!pip install requests\n",
    "!pip install BeautifulSoup4\n",
    "!pip install HTMLParser\n",
    "!pip install rdflib\n",
    "!pip install cloudscraper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "irPnmIK4eMJd"
   },
   "source": [
    "##  Exercise 1\n",
    "\n",
    "Even if web pages do not use microformat, interesting data can often be extracted from the HTML. You may use packages such as BeautifulSoup to extract arbitrary pieces of data from any HTML page.\n",
    "The example below shows how we can find the URL of first image in the infobox table of the wikipedia page on Amsterdam. Tip: compare the code below with HTML source code of the wikipedia page: the image url is in the \"src\" attribute of the \"img\" element of in the \"table\" element with class=\"infobox\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9gpHw90keMJf",
    "outputId": "7ae1fe64-8d85-4a47-cfdf-422284954d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Imagen_de_los_canales_conc%C3%A9ntricos_en_%C3%81msterdam.png/268px-Imagen_de_los_canales_conc%C3%A9ntricos_en_%C3%81msterdam.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# This script requires you to add a url of a page with geotags to the commandline, e.g.\n",
    "# python geo.py 'http://en.wikipedia.org/wiki/Amsterdam'\n",
    "URL = 'https://en.wikipedia.org/wiki/Amsterdam'\n",
    "\n",
    "req = requests.get(URL, headers={'User-Agent' : \"Social Web Course Student\"})\n",
    "soup = BeautifulSoup(req.text)\n",
    "# print(req.text)\n",
    "image1 = soup.findAll('table', class_='infobox')[0].find('img')\n",
    "print(image1['src'])  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting coordinates from a webpage and reformatting them in the geo microformat (based on Example 8-1 in Mining the Social Web). Note that wikipages may encode long/lat information in different ways. On of the ways used by the Amsterdam wikipedia page is in a span element that is not shown to the user: \n",
    "<span class=\"geo\">52.367; 4.900</span>\n",
    "This span element has a single child: len(geoTag == 1) and no further structure, we have to manually get the long/lat by splitting the string on the ';' semicolon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LtHtQT9PeMJl",
    "outputId": "8a7f7b52-cdb2-409f-b3f0-ee7adf60a9f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"geo\">52.37278; 4.89361</span>\n",
      "Location is at 52.37278 4.89361\n"
     ]
    }
   ],
   "source": [
    "\n",
    "geoTag = soup.find(True, 'geo')\n",
    "print(geoTag)\n",
    "\n",
    "if geoTag and len(geoTag) > 1:\n",
    "        lat = geoTag.find(True, 'latitude').string\n",
    "        lon = geoTag.find(True, 'longitude').string\n",
    "        print ('Location is at'), lat, lon\n",
    "elif geoTag and len(geoTag) == 1:\n",
    "        (lat, lon) = geoTag.string.split(';')\n",
    "        (lat, lon) = (lat.strip(), lon.strip())\n",
    "        print (('Location is at'), lat, lon)\n",
    "else:\n",
    "        print ('Location not found')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8S_bXnjveMJp"
   },
   "source": [
    "### Task 1\n",
    "\n",
    "Can you convert the output of Exercise 1 into KML? Here is the KML documentation: https://developers.google.com/kml/documentation/?csw=1 and here you can find a simple example of how it is used: https://renenyffenegger.ch/notes/tools/Google-Earth/kml/index\n",
    "\n",
    "Visualise the point in Google Maps using the following code example: https://developers.google.com/maps/documentation/javascript/examples/layer-kml-features\n",
    "You will have to create your own KML file for the custom map layer, and provide a URL to the KML file inside the JavaScript code, which means that you have to upload the file somewhere. You can use a service like http://pastebin.com/ to obtain a URL for your KML file —> paste the code there and request the RAW format URL; use this one in this Task1. If it fails to work you can also use KML viewer websites like https://kmzview.com/.\n",
    "\n",
    "Is KML a microformat, why (not)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.9.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<kml xmlns=\"http://www.opengis.net/kml/2.2\">\n",
      " <Placemark>\n",
      "  <name>\n",
      "   Our New Social Web Placemark\n",
      "  </name>\n",
      "  <description>\n",
      "   Oh look it works!\n",
      "  </description>\n",
      "  <Point>\n",
      "   <coordinates>\n",
      "    4.89361, 52.37278, 0\n",
      "   </coordinates>\n",
      "  </Point>\n",
      " </Placemark>\n",
      "</kml>\n"
     ]
    }
   ],
   "source": [
    "KML_FILENAME = \"./A2_Task1_KML.kml\"\n",
    "\n",
    "task1_soup = BeautifulSoup('<?xml version=\"1.0\" encoding=\"UTF-8\"?><kml xmlns=\"http://www.opengis.net/kml/2.2\"></kml>' ,features='xml')\n",
    "\n",
    "task1_soup.find('kml').append(task1_soup.new_tag(\"Placemark\"))\n",
    "\n",
    "# Make name tag\n",
    "task1_soup.find(\"Placemark\").append(task1_soup.new_tag(\"name\"))\n",
    "task1_soup.find(\"name\").append(task1_soup.new_string(\"Our New Social Web Placemark\"))\n",
    "\n",
    "# Make description\n",
    "task1_soup.find(\"Placemark\").append(task1_soup.new_tag(\"description\"))\n",
    "task1_soup.find(\"description\").append(task1_soup.new_string(\"Oh look it works!\"))\n",
    "\n",
    "# Make point\n",
    "task1_soup.find(\"Placemark\").append(task1_soup.new_tag(\"Point\"))\n",
    "\n",
    "# Put coordinates in point\n",
    "task1_soup.find(\"Point\").append(task1_soup.new_tag(\"coordinates\"))\n",
    "task1_soup.find(\"coordinates\").append(task1_soup.new_string(f'{lon}, {lat}, 0'))\n",
    "\n",
    "print(task1_soup.prettify())\n",
    "with open(KML_FILENAME, \"w\") as f:\n",
    "    f.write(task1_soup.prettify())\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kUnka7EyeMJp"
   },
   "source": [
    "## Exercise 2 \n",
    "In order to find information in the web we can use microformats such as [hRecipe](https://microformats.org/wiki/hrecipe) or Schema.org's [Recipe](https://schema.org/Recipe). But first, we'll show you how to find arbitrary tags in a webpage.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "b0pBs-PVeMJq"
   },
   "source": [
    "### Task 2 \n",
    "Parsing data for a <sub><sup>veggie</sup></sub> spaghetti alla carbonara recipe (from Example 2-7 in Mining the Social Web)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cloudscraper\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# A yummy webpage (feel free to change to your likings.)\n",
    "URL = \"https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara\"\n",
    "\n",
    "# Create a CloudScraper object\n",
    "scraper = cloudscraper.create_scraper()\n",
    "\n",
    "# Use the CloudScraper object to fetch the HTML content\n",
    "response = scraper.get(URL)\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Now you can work with the 'soup' object as you did before\n",
    "listchildren = list(soup.children)\n",
    "#print(listchildren)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IhdMwqykeMJt"
   },
   "source": [
    "We can find any element in the page through *css tag selectors*\n",
    "You can find them all [here](https://www.w3schools.com/cssref/css_selectors.asp), but shortly these are \".\" for classes, # for ids and plain text for the element name.\n",
    "\n",
    "\n",
    "You can also combine them, so that looking for \".class1.class2\" would select all elements displaying both classes. For a deeper overview please check the above link (or google \"html tag selectors\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<title>Vegetarian Carbonara – A Couple Cooks</title>\n"
     ]
    }
   ],
   "source": [
    "print(len(listchildren)) # we can see here how many children the html doc has got.\n",
    "title_unparsed = soup.select_one(\"title\")\n",
    "#show the title element\n",
    "print(title_unparsed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so pretty.... Use the text method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetarian Carbonara – A Couple Cooks\n"
     ]
    }
   ],
   "source": [
    "print(title_unparsed.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website has a block of JSON-LD data embedded. Try to see if you can find it in the soup object.\n",
    "We can load the JSON-LD script to work with it easier.\n",
    "Lets get a list of the ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 pound spaghetti noodles\n",
      "½ cup smoked mozzarella cheese\n",
      "½ cup grated Parmesan cheese, plus more for serving\n",
      "4 egg yolks\n",
      "1 cup frozen Earthbound Farm Organic peas\n",
      "8 cups Earthbound Farm Organic spinach\n",
      "3 tablespoons butter\n",
      "Kosher salt\n",
      "Fresh ground black pepper\n"
     ]
    }
   ],
   "source": [
    "# Find the script tag containing the JSON-LD data\n",
    "json_ld_script = soup.find(\"script\", {\"class\": \"yoast-schema-graph\"})\n",
    "\n",
    "# Extract the content of the script tag\n",
    "script_content = json_ld_script.string\n",
    "\n",
    "# Load the JSON data from the script content\n",
    "data = json.loads(script_content)\n",
    "\n",
    "# Access the \"recipeIngredient\" list\n",
    "recipe_ingredients = data[\"@graph\"][7][\"recipeIngredient\"]\n",
    "\n",
    "# Print the list of ingredients\n",
    "for ingredient in recipe_ingredients:\n",
    "    print(ingredient)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also print out the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a large pot, combine 6 quarts of water with 2 tablespoons kosher salt and bring it to a boil.\n",
      "Grate the Parmesan and mozzarella cheese. Carefully separate four egg yolks and set aside.\n",
      "Once boiling, add the pasta and cook until the pasta is just about al dente, about 7 minutes; then add peas and spinach and cook for 1 minute. Reserve 1 cup cooking water, and then drain the pasta and vegetables.\n",
      "In a skillet, melt the butter, then stir in the cheeses, ¼ cup pasta water, and ¼ teaspoon kosher salt. Stir in the pasta and vegetables until creamy over low heat, adding more pasta water if necessary (note that the mozzarella will stick together in some places).\n",
      "To serve, top each pasta serving with a whole egg yolk and additional Parmesan cheese, and stir the yolk into the pasta at the table (if you are uncomfortable serving egg yolks at the table, stir the egg yolks into the pasta in the skillet to heat them through). Serve immediately. (Note that the mozzarella cheese can become gummy the longer the pasta sits, so eat immediately if possible. Leftovers can be reheated in a skillet, but may not have the same creamy texture.)\n"
     ]
    }
   ],
   "source": [
    "recipe_instructions= data[\"@graph\"][7][\"recipeInstructions\"]\n",
    "#the instructions list contains dictionaries as elements, take a look at how the list is organized\n",
    "for step in recipe_instructions:\n",
    "    print(step[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Websites are going to be structured differently. Look at the following JSON-DL snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_example = {\n",
    "    \"title\": \"The anarchist cookbook\",\n",
    "    \"recipeInstructions\": \"<ol class=\\\"recipeSteps\\\"><li>Cook the linguine according to the packet instructions. </li><li>Meanwhile, carefully crack the eggs into a small bowl and beat them with a fork. Season with a little black pepper, then stir in the ricotta finely grate in most of the lemon zest. </li><li>When the pasta has 3 minutes left, add the peas. Reserve a little cooking water, then drain the linguine and peas, and return to the pan. </li><li>Stir in the egg mixture and spinach with a wooden spoon – they'll cook gently in the residual heat. Add a little pasta water to loosen, if needed. </li><li>Share between bowls and serve with a green salad.</li></ol>\",\n",
    "    \"ingredients\": [\"a lot of effort\", \"the right mindset\"]\n",
    "}\n",
    "\n",
    "recipe_instructions = json_example[\"recipeInstructions\"]\n",
    "example_soup = BeautifulSoup(recipe_instructions, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cook the linguine according to the packet instructions.', 'Meanwhile, carefully crack the eggs into a small bowl and beat them with a fork. Season with a little black pepper, then stir in the ricotta finely grate in most of the lemon zest.', 'When the pasta has 3 minutes left, add the peas. Reserve a little cooking water, then drain the linguine and peas, and return to the pan.', \"Stir in the egg mixture and spinach with a wooden spoon – they'll cook gently in the residual heat. Add a little pasta water to loosen, if needed.\", 'Share between bowls and serve with a green salad.']\n"
     ]
    }
   ],
   "source": [
    "#to get a nice and clean list of the instructions, step by step\n",
    "#we can use the find method to get the first \"ol\" element with attribute \"class..\" and then use find_all to get all list elements in there\n",
    "#then we can strip the list items to obtain the instructions\n",
    "list_items = example_soup.find('ol', class_='recipeSteps').find_all('li')\n",
    "instructions = [item.get_text(strip=True) for item in list_items]\n",
    "print(instructions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RYb6WtXYeMJ6"
   },
   "source": [
    "## Task 2.1\n",
    "Now it's your turn. Create a function that can scrape any recipe webpage from the same website (other websites will have different class tags). \n",
    "\n",
    "Make sure to:\n",
    "\n",
    "- return itemized content (e.g. ingredients) in a list. You may want to use a list comprehension here.\n",
    "- Not all items have been cleaned of their html markdown (see variables ```ingredients``` vs. ```instructions_unparsed```. Make sure to return a list with human readable content (i.e. by using the ```.text``` attribute).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Vegetarian Carbonara – A Couple Cooks', 'ingredients': [{'@type': 'Article', '@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#article', 'isPartOf': {'@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/'}, 'author': {'name': 'Sonja Overhiser', '@id': 'https://www.acouplecooks.com/#/schema/person/d3a3c9869553a70f725f007b4656b09b'}, 'headline': 'Vegetarian Carbonara', 'datePublished': '2018-04-04T08:00:29+00:00', 'dateModified': '2021-12-05T02:15:20+00:00', 'wordCount': 804, 'commentCount': 12, 'publisher': {'@id': 'https://www.acouplecooks.com/#organization'}, 'image': {'@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#primaryimage'}, 'thumbnailUrl': 'https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-003.jpg', 'keywords': ['Carbonara', 'Cheese', 'Earth', 'Earth-Saving', 'Easy', 'Mediterranean', 'Mozzarella', 'Parmesan', 'Pasta', 'Peas', 'Quick', 'Spaghetti', 'Spinach', 'Spring', 'Vegetarian', 'Weeknight Meal'], 'articleSection': ['Dinner Recipes', 'Fast Dinner Ideas', 'Recipes'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/', 'url': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/', 'name': 'Vegetarian Carbonara – A Couple Cooks', 'isPartOf': {'@id': 'https://www.acouplecooks.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#primaryimage'}, 'image': {'@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#primaryimage'}, 'thumbnailUrl': 'https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-003.jpg', 'datePublished': '2018-04-04T08:00:29+00:00', 'dateModified': '2021-12-05T02:15:20+00:00', 'description': 'This vegetarian carbonara is quick and delicious; an egg yolk is stirred into the pasta to create a sauce, and smoked mozarella is used instead of bacon.', 'breadcrumb': {'@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#primaryimage', 'url': 'https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-003.jpg', 'contentUrl': 'https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-003.jpg', 'width': 700, 'height': 875}, {'@type': 'BreadcrumbList', '@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.acouplecooks.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Recipes', 'item': 'https://www.acouplecooks.com/category/recipes/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Fast Dinner Ideas', 'item': 'https://www.acouplecooks.com/category/recipes/fast-dinner-ideas/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Vegetarian Carbonara'}]}, {'@type': 'WebSite', '@id': 'https://www.acouplecooks.com/#website', 'url': 'https://www.acouplecooks.com/', 'name': 'A Couple Cooks', 'description': 'Recipes worth repeating.', 'publisher': {'@id': 'https://www.acouplecooks.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.acouplecooks.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.acouplecooks.com/#organization', 'name': 'A Couple Cooks', 'url': 'https://www.acouplecooks.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.acouplecooks.com/#/schema/logo/image/', 'url': 'https://www.acouplecooks.com/wp-content/uploads/2021/06/social.jpg', 'contentUrl': 'https://www.acouplecooks.com/wp-content/uploads/2021/06/social.jpg', 'width': 1200, 'height': 630, 'caption': 'A Couple Cooks'}, 'image': {'@id': 'https://www.acouplecooks.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/groups/193375798111474/', 'https://twitter.com/acouplecooks', 'https://www.instagram.com/acouplecooks/', 'https://www.pinterest.com/acouplecooks/', 'https://www.youtube.com/aCoupleCooksTV']}, {'@type': 'Person', '@id': 'https://www.acouplecooks.com/#/schema/person/d3a3c9869553a70f725f007b4656b09b', 'name': 'Sonja Overhiser', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.acouplecooks.com/#/schema/person/image/', 'url': 'https://www.acouplecooks.com/wp-includes/images/blank.gif', 'contentUrl': 'https://www.acouplecooks.com/wp-includes/images/blank.gif', 'caption': 'Sonja Overhiser'}, 'sameAs': ['https://www.facebook.com/aCoupleCooks'], 'url': 'https://www.acouplecooks.com/author/skuhnau/'}, {'@context': 'https://schema.org/', '@type': 'Recipe', 'name': 'Vegetarian Carbonara', 'description': 'This vegetarian carbonara is quick and delicious; an egg yolk is stirred into the pasta to create a sauce, and smoked mozarella is used instead of bacon.', 'author': {'@type': 'Person', 'name': 'a Couple Cooks', 'url': 'https://www.acouplecooks.com/about/'}, 'keywords': 'vegetarian carbonara, vegetarian pasta recipe', 'image': ['https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-001-225x225.jpg', 'https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-001-260x195.jpg', 'https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-001-320x180.jpg', 'https://www.acouplecooks.com/wp-content/uploads/2016/04/Spring-Vegetarian-Carbonara-001.jpg'], 'url': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/', 'recipeIngredient': ['1 pound spaghetti noodles', '½ cup smoked mozzarella cheese', '½ cup grated Parmesan cheese, plus more for serving', '4 egg yolks', '1 cup frozen Earthbound Farm Organic peas', '8 cups Earthbound Farm Organic spinach', '3 tablespoons butter', 'Kosher salt', 'Fresh ground black pepper'], 'recipeInstructions': [{'@type': 'HowToStep', 'text': 'In a large pot, combine 6 quarts of water with 2 tablespoons kosher salt and bring it to a boil.', 'url': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#instruction-step-1'}, {'@type': 'HowToStep', 'text': 'Grate the Parmesan and mozzarella cheese. Carefully separate four egg yolks and set aside.', 'url': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#instruction-step-2'}, {'@type': 'HowToStep', 'text': 'Once boiling, add the pasta and cook until the pasta is just about al dente, about 7 minutes; then add peas and spinach and cook for 1 minute. Reserve 1 cup cooking water, and then drain the pasta and vegetables.', 'url': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#instruction-step-3'}, {'@type': 'HowToStep', 'text': 'In a skillet, melt the butter, then stir in the cheeses, ¼ cup pasta water, and ¼ teaspoon kosher salt. Stir in the pasta and vegetables until creamy over low heat, adding more pasta water if necessary (note that the mozzarella will stick together in some places).', 'url': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#instruction-step-4'}, {'@type': 'HowToStep', 'text': 'To serve, top each pasta serving with a whole egg yolk and additional Parmesan cheese, and stir the yolk into the pasta at the table (if you are uncomfortable serving egg yolks at the table, stir the egg yolks into the pasta in the skillet to heat them through). Serve immediately. (Note that the mozzarella cheese can become gummy the longer the pasta sits, so eat immediately if possible. Leftovers can be reheated in a skillet, but may not have the same creamy texture.)', 'url': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#instruction-step-5'}], 'prepTime': 'PT15M', 'cookTime': 'PT10M', 'totalTime': 'PT25M', 'recipeYield': '4', 'recipeCategory': 'Main Dish', 'cookingMethod': 'Stovetop', 'recipeCuisine': 'Italian', 'aggregateRating': {'@type': 'AggregateRating', 'reviewCount': '1', 'ratingValue': '5'}, 'datePublished': '2018-04-04', '@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#recipe', 'isPartOf': {'@id': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/#article'}, 'mainEntityOfPage': 'https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara/'}], 'instructions': ['In a large pot, combine 6 quarts of water with 2 tablespoons kosher salt and bring it to a boil.', 'Grate the Parmesan and mozzarella cheese. Carefully separate four egg yolks and set aside.', 'Once boiling, add the pasta and cook until the pasta is just about al dente, about 7 minutes; then add peas and spinach and cook for 1 minute. Reserve 1 cup cooking water, and then drain the pasta and vegetables.', 'In a skillet, melt the butter, then stir in the cheeses, ¼ cup pasta water, and ¼ teaspoon kosher salt. Stir in the pasta and vegetables until creamy over low heat, adding more pasta water if necessary (note that the mozzarella will stick together in some places).', 'To serve, top each pasta serving with a whole egg yolk and additional Parmesan cheese, and stir the yolk into the pasta at the table (if you are uncomfortable serving egg yolks at the table, stir the egg yolks into the pasta in the skillet to heat them through). Serve immediately. (Note that the mozzarella cheese can become gummy the longer the pasta sits, so eat immediately if possible. Leftovers can be reheated in a skillet, but may not have the same creamy texture.)']}\n"
     ]
    }
   ],
   "source": [
    "#Here you can see the solution for our example website\n",
    "\n",
    "URL = \"https://www.acouplecooks.com/spring-vegetarian-spaghetti-carbonara\"\n",
    "\n",
    "def parse_website(url):\n",
    "    # Create a CloudScraper object\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "\n",
    "    # Use the CloudScraper object to fetch the HTML content\n",
    "    response = scraper.get(URL)\n",
    "\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    #Get the title\n",
    "    title_unparsed = soup.select_one(\"title\")\n",
    "    fn = title_unparsed.text\n",
    "    \n",
    "    json_ld_script = soup.find(\"script\", {\"class\": \"yoast-schema-graph\"})\n",
    "\n",
    "    # Extract the content of the script tag\n",
    "    script_content = json_ld_script.string\n",
    "\n",
    "    # Load the JSON data from the script content\n",
    "    data = json.loads(script_content)\n",
    "\n",
    "    # Access the \"recipeIngredient\" list\n",
    "    recipe_ingredients = data[\"@graph\"]\n",
    "    \n",
    "    ingredients = [ingredient for ingredient in recipe_ingredients]\n",
    "    \n",
    "    #Access the instructions\n",
    "    recipe_instructions= data[\"@graph\"][7][\"recipeInstructions\"]\n",
    "    #the instructions list contains dictionaries as elements, take a look at how the list is organized\n",
    "    instructions = [step[\"text\"] for step in recipe_instructions]\n",
    "\n",
    "    return {'name': fn,\n",
    "            'ingredients': ingredients,\n",
    "            'instructions': instructions,\n",
    "            }\n",
    "    \n",
    "recipe = parse_website(URL)\n",
    "print (recipe)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "UQu9ecLEeMJ6",
    "outputId": "a8aa0e14-a8fb-4279-cf32-8dca97ab3412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Vegetarian carbonara recipe | Jamie Oliver pasta recipes', 'ingredients': ['400 g dried linguine', '4 large free-range eggs', '2 tablespoons soft ricotta cheese', '1  lemon', '100 g fresh or frozen peas', '100 g baby spinach'], 'instructions': ['Cook the linguine according to the packet instructions.', 'Meanwhile, carefully crack the eggs into a small bowl and beat them with \\na fork. Season with a little black pepper, then stir in the ricotta finely grate in most of the lemon zest.', 'When the pasta has 3 minutes left, add the peas. Reserve a little cooking water, then drain the linguine and peas, and return to the pan.', 'Stir in the egg mixture and spinach with a wooden spoon – they’ll cook gently in the residual heat. Add a little pasta water to loosen, if needed.', 'Share between bowls and serve with a green salad.']}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import cloudscraper\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Pass in a URL containing hRecipe, such as\n",
    "# https://www.jamieoliver.com/recipes/pasta-recipes/veggie-carbonara/\n",
    "\n",
    "URL = \"https://www.jamieoliver.com/recipes/pasta-recipes/veggie-carbonara/\"\n",
    "\n",
    "# Parse out some of the pertinent information for a recipe.\n",
    "# See http://microformats.org/wiki/hrecipe.\n",
    "\n",
    "#Solution for jamie oliver\n",
    "def parse_website(url):\n",
    "    # Create a CloudScraper object\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "\n",
    "    # Use the CloudScraper object to fetch the HTML content\n",
    "    response = scraper.get(url)\n",
    "\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    #Get the title\n",
    "    title_unparsed = soup.select_one(\"title\")\n",
    "    fn = title_unparsed.text\n",
    "    \n",
    "    json_ld_script = soup.find(\"script\", {'type':'application/ld+json'})\n",
    "\n",
    "    # Extract the content of the script tag\n",
    "    script_content = json_ld_script.string\n",
    "\n",
    "    # Load the JSON data from the script content\n",
    "    data = json.loads(script_content)\n",
    "\n",
    "    # Access the \"recipeIngredient\" list\n",
    "    recipe_ingredients = data[\"recipeIngredient\"]\n",
    "    ingredients = [ingredient.strip() for ingredient in recipe_ingredients]\n",
    "    \n",
    "    #Access the instructions\n",
    "    recipe_instructions= data[\"recipeInstructions\"]\n",
    "    list_items = BeautifulSoup(recipe_instructions, 'html.parser').find('ol').find_all('li')\n",
    "    instructions = [item.get_text(strip=True) for item in list_items]\n",
    "    \n",
    "    #the instructions list contains dictionaries as elements, take a look at how the list is organized\n",
    "    # instructions = [step[\"text\"] for step in recipe_instructions]\n",
    "\n",
    "    return {\n",
    "            'name': fn,\n",
    "            'ingredients': ingredients,\n",
    "            'instructions': instructions,\n",
    "            }\n",
    "    \n",
    "recipe = parse_website(URL)\n",
    "print (recipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ccURluAIeMJ8"
   },
   "source": [
    "But How can we get information not only from one website,  but from all? \n",
    "\n",
    "The answer: microformats.\n",
    "\n",
    "But rather than extracting with information manually from the schema.org or hRecipe microformats, we can use a package, ```scrape-schema-recipe``` \n",
    "\n",
    "Feel free to experiment with it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EBY-y_GreMJ8"
   },
   "source": [
    "### Task 2.2\n",
    "hRecipe is a microformat specifically created for recipes.\n",
    "Can you for example easily compare different dessert recipe ingredients? For inspiration you can look back at the exercises you did in Hands-on session 1 where you compared different sets of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.9.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from prettytable) (0.2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrape_schema_recipe in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.2.2)\n",
      "Requirement already satisfied: setuptools>=39.2.0 in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from scrape_schema_recipe) (65.5.0)\n",
      "Requirement already satisfied: extruct in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scrape_schema_recipe) (0.16.0)\n",
      "Requirement already satisfied: isodate>=0.5.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scrape_schema_recipe) (0.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scrape_schema_recipe) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from isodate>=0.5.1->scrape_schema_recipe) (1.16.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct->scrape_schema_recipe) (4.9.3)\n",
      "Requirement already satisfied: pyrdfa3 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct->scrape_schema_recipe) (3.5.3)\n",
      "Requirement already satisfied: mf2py in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct->scrape_schema_recipe) (1.1.3)\n",
      "Requirement already satisfied: w3lib in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct->scrape_schema_recipe) (2.1.2)\n",
      "Requirement already satisfied: html-text>=0.5.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct->scrape_schema_recipe) (0.5.2)\n",
      "Requirement already satisfied: jstyleson in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct->scrape_schema_recipe) (0.0.2)\n",
      "Requirement already satisfied: rdflib>=6.0.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct->scrape_schema_recipe) (7.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->scrape_schema_recipe) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->scrape_schema_recipe) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->scrape_schema_recipe) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->scrape_schema_recipe) (2022.12.7)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rdflib>=6.0.0->extruct->scrape_schema_recipe) (3.0.9)\n",
      "Requirement already satisfied: html5lib>=1.0.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mf2py->extruct->scrape_schema_recipe) (1.1)\n",
      "Requirement already satisfied: BeautifulSoup4>=4.6.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mf2py->extruct->scrape_schema_recipe) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from BeautifulSoup4>=4.6.0->mf2py->extruct->scrape_schema_recipe) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from html5lib>=1.0.1->mf2py->extruct->scrape_schema_recipe) (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install prettytable\n",
    "!pip install scrape_schema_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+--------+\n",
      "| Recipe1  | Count1 | Recipe2  | Count2 |\n",
      "+----------+--------+----------+--------+\n",
      "| teaspoon |   3    |   plus   |   2    |\n",
      "|  ground  |   3    |  extra   |   2    |\n",
      "|  large   |   2    |  sugar   |   2    |\n",
      "| pumpkin  |   2    | vanilla  |   2    |\n",
      "|  sugar   |   2    | cherries |   2    |\n",
      "|  double  |   2    |  plain   |   1    |\n",
      "|  cream   |   2    |  flour   |   1    |\n",
      "|  serve   |   2    | dusting  |   1    |\n",
      "|  squash  |   1    |  icing   |   1    |\n",
      "|   such   |   1    |  orange  |   1    |\n",
      "+----------+--------+----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "import scrape_schema_recipe\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# get the top 10 words from the ingredients\n",
    "def get_words(ingredients):\n",
    "  words = []\n",
    "  for t in ingredients:\n",
    "    for w in t.split():\n",
    "      if len(w) > 3:\n",
    "        # from https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "        w = w.translate(str.maketrans('', '', string.punctuation)) \n",
    "        words.append(w)\n",
    "\n",
    "  for item in [words]:\n",
    "    c = Counter(item)\n",
    "\n",
    "  return c.most_common()[:10]\n",
    "\n",
    "\n",
    "\n",
    "url = 'https://www.jamieoliver.com/recipes/butternut-squash-recipes/ultimate-pumpkin-pie/'\n",
    "recipe_list = scrape_schema_recipe.scrape_url(url, python_objects=True)\n",
    "recipe1 = recipe_list[0]\n",
    "\n",
    "url = 'https://www.jamieoliver.com/recipes/fruit-recipes/frozen-sour-cherry-berry-pie/'\n",
    "recipe_list = scrape_schema_recipe.scrape_url(url, python_objects=True)\n",
    "recipe2 = recipe_list[0]\n",
    "\n",
    "words1 = get_words(recipe1['recipeIngredient'])\n",
    "words2 = get_words(recipe2['recipeIngredient'])\n",
    "\n",
    "# join the two tuple lists\n",
    "for i in range(0, len(words1)):\n",
    "  words1[i] = words1[i] + words2[i]\n",
    "\n",
    "# draw the table\n",
    "pt = PrettyTable(field_names=['Recipe1', 'Count1', 'Recipe2', 'Count2'])\n",
    "[ pt.add_row(r) for r in words1 ]\n",
    "print(pt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "n-J8fiLbeMJ9"
   },
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7XBeqJHVeMJ9"
   },
   "source": [
    "Schema.org is one of the most widely used annotations formats. Schema.org is a multipurpose  template that has been created by a consortium consisting of Yahoo!, Google and Microsoft. It can describe entities, events, products etc. Check out the vocabulary specs on Schema.org."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fiw8JClyeMJ-"
   },
   "source": [
    "### Task 3\n",
    "\n",
    "Parsing schema.org microdata. To parse this data you need to install the rdflib-microdata package, which you have done in one of the previous steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "X2zr3fOOeMJ-",
    "outputId": "d123f981-d73f-470f-b5e9-8735819f894b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dbpedia.org/resource/Micheal_Jackson http://xmlns.com/foaf/0.1/isPrimaryTopicOf http://en.wikipedia.org/wiki/Micheal_Jackson\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://dbpedia.org/property/wikiPageUsesTemplate http://dbpedia.org/resource/Template:R_from_misspelling\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://dbpedia.org/ontology/wikiPageRedirects http://dbpedia.org/resource/Michael_Jackson\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://dbpedia.org/ontology/wikiPageLength 68\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://dbpedia.org/ontology/wikiPageID 14995602\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://www.w3.org/ns/prov#wasDerivedFrom http://en.wikipedia.org/wiki/Micheal_Jackson?oldid=1056738079&ns=0\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://dbpedia.org/ontology/wikiPageRevisionID 1056738079\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://www.w3.org/2000/01/rdf-schema#label Micheal Jackson\n",
      "http://dbpedia.org/resource/Micheal_Jackson http://dbpedia.org/ontology/wikiPageWikiLink http://dbpedia.org/resource/Michael_Jackson\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "# Source: https://www.youtube.com/watch?v=sCU214rbRZ0\n",
    "# Pass in a URL containing Schema.org microformats\n",
    "URL = \"http://dbpedia.org/resource/Micheal_Jackson\"\n",
    "\n",
    "# Initialize a graph\n",
    "g = Graph()\n",
    "\n",
    "# Parse in an RDF file graph dbpedia\n",
    "result = g.parse(location=URL)\n",
    "\n",
    "# Loop through first 10 triples in the graph\n",
    "for index, (sub, pred, obj) in enumerate(g):\n",
    "    print(sub, pred, obj)\n",
    "    if index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hrQ2EuY5JAn1",
    "outputId": "eba60ebb-7ac5-4451-c16e-3f68e66af7f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 9 facts\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the Graph\n",
    "print(f'Graph has {len(g)} facts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "IAO1JllwJMqO",
    "outputId": "08f5e32d-d1a6-4a30-878a-ce7b768a8811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix ns1: <http://dbpedia.org/property/> .\n",
      "@prefix ns2: <http://dbpedia.org/ontology/> .\n",
      "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<http://dbpedia.org/resource/Micheal_Jackson> rdfs:label \"Micheal Jackson\"@en ;\n",
      "    ns2:wikiPageID 14995602 ;\n",
      "    ns2:wikiPageLength \"68\"^^xsd:nonNegativeInteger ;\n",
      "    ns2:wikiPageRedirects <http://dbpedia.org/resource/Michael_Jackson> ;\n",
      "    ns2:wikiPageRevisionID 1056738079 ;\n",
      "    ns2:wikiPageWikiLink <http://dbpedia.org/resource/Michael_Jackson> ;\n",
      "    ns1:wikiPageUsesTemplate <http://dbpedia.org/resource/Template:R_from_misspelling> ;\n",
      "    prov:wasDerivedFrom <http://en.wikipedia.org/wiki/Micheal_Jackson?oldid=1056738079&ns=0> ;\n",
      "    foaf:isPrimaryTopicOf <http://en.wikipedia.org/wiki/Micheal_Jackson> .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the entire Graph in the RDF Turtle format\n",
    "print(g.serialize(format='ttl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dzbynasAeMKA"
   },
   "source": [
    "### Task 3.1 \n",
    "Compare the schema.org information about a band on last.fm to the Facebook Open Graph information about the same band from Facebook. What are the differences? Which format do you think supports better interoperability? In particular, refer to the Microformat specifications indicated in the box on the top right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: extruct in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.16.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (4.9.3)\n",
      "Requirement already satisfied: pyrdfa3 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (3.5.3)\n",
      "Requirement already satisfied: mf2py in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (1.1.3)\n",
      "Requirement already satisfied: w3lib in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (2.1.2)\n",
      "Requirement already satisfied: html-text>=0.5.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (0.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (1.16.0)\n",
      "Requirement already satisfied: jstyleson in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (0.0.2)\n",
      "Requirement already satisfied: rdflib>=6.0.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from extruct) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rdflib>=6.0.0->extruct) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rdflib>=6.0.0->extruct) (3.0.9)\n",
      "Requirement already satisfied: html5lib>=1.0.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mf2py->extruct) (1.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mf2py->extruct) (2.31.0)\n",
      "Requirement already satisfied: BeautifulSoup4>=4.6.0 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mf2py->extruct) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from BeautifulSoup4>=4.6.0->mf2py->extruct) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from html5lib>=1.0.1->mf2py->extruct) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.18.4->mf2py->extruct) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.18.4->mf2py->extruct) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.18.4->mf2py->extruct) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cursa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.18.4->mf2py->extruct) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\cursa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install extruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://schema.org/MusicGroup\n",
      "- image: https://lastfm.freetls.fastly.net/i/u/ar0/3c5c0026bea779f2fd2635b714458935.jpg\n",
      "- name: Pinguini Tattici Nucleari\n",
      "- url: /music/Pinguini+Tattici+Nucleari\n",
      "- Albums:\n",
      "  - Rubami La Notte - Single (/music/Pinguini+Tattici+Nucleari/Rubami+La+Notte+-+Single)\n",
      "  - AHIA! (/music/Pinguini+Tattici+Nucleari/AHIA!)\n",
      "  - Fuori Dall'Hype Ringo Starr (/music/Pinguini+Tattici+Nucleari/Fuori+Dall%27Hype+Ringo+Starr)\n",
      "  - Fake News (/music/Pinguini+Tattici+Nucleari/Fake+News)\n",
      "  - Fuori dall'hype (/music/Pinguini+Tattici+Nucleari/Fuori+dall%27hype)\n",
      "- Tracks:\n",
      "  - Rubami la Notte\n",
      "  - Rubami la Notte\n",
      "  - Pastello Bianco\n",
      "  - Ricordi\n",
      "  - Ridere\n",
      "  - Giovani Wannabe\n",
      "  - Ringo Starr\n",
      "  - Scooby Doo\n",
      "  - Scrivile Scemo\n",
      "  - Coca zero\n",
      "  - Lake Washington Boulevard\n",
      "http://schema.org/MusicGroup\n",
      "- name: GAZZELLE\n",
      "- url: /music/GAZZELLE\n",
      "http://schema.org/MusicGroup\n",
      "- name: Cesare Cremonini\n",
      "- url: /music/Cesare+Cremonini\n",
      "http://schema.org/MusicGroup\n",
      "- name: Tananai\n",
      "- url: /music/Tananai\n",
      "http://schema.org/MusicGroup\n",
      "- name: GAZZELLE\n",
      "- url: /music/GAZZELLE\n",
      "http://schema.org/MusicGroup\n",
      "- name: Cesare Cremonini\n",
      "- url: /music/Cesare+Cremonini\n",
      "http://schema.org/MusicGroup\n",
      "- name: Tananai\n",
      "- url: /music/Tananai\n",
      "http://schema.org/MusicGroup\n",
      "- name: Fulminacci\n",
      "- url: /music/Fulminacci\n",
      "http://schema.org/MusicGroup\n",
      "- name: Eugenio in via di gioia\n",
      "- url: /music/Eugenio+in+via+di+gioia\n",
      "http://schema.org/MusicGroup\n",
      "- name: Fedez\n",
      "- url: /music/Fedez\n",
      "http://schema.org/Organization\n",
      "- url: https://www.last.fm\n",
      "- sameAs: ['https://www.facebook.com/lastfm', 'https://twitter.com/lastfm', 'https://www.instagram.com/last_fm', 'https://www.youtube.com/user/lastfm']\n",
      "- name: Last.fm\n"
     ]
    }
   ],
   "source": [
    "# Data from LastFM\n",
    "\n",
    "import extruct\n",
    "\n",
    "LASTFM_URL = \"https://www.last.fm/music/Pinguini+Tattici+Nucleari\"\n",
    "req_lastfm = requests.get(LASTFM_URL, headers={'User-Agent' : \"Social Web Course Student\"})\n",
    "metadata_lastfm = extruct.extract(htmlstring_or_tree=req_lastfm.text)\n",
    "\n",
    "# Go through all the items\n",
    "for item_lastfm in metadata_lastfm[\"microdata\"]:\n",
    "    print(item_lastfm[\"type\"])\n",
    "    itemtype = item_lastfm[\"type\"].split(\"/\")[-1]\n",
    "    \n",
    "    if 'properties' in item_lastfm:\n",
    "        props = item_lastfm['properties']\n",
    "        \n",
    "        # Go through all the info about the entry\n",
    "        for prop in props:\n",
    "            \n",
    "            # Go through the albums\n",
    "            if prop == 'album':\n",
    "                print(\"- Albums:\")\n",
    "                for album in props[prop]:\n",
    "                    print(f'  - {album[\"properties\"][\"name\"]} ({album[\"properties\"][\"url\"]})')\n",
    "                    \n",
    "                    \n",
    "            #Go through the tracks\n",
    "            elif prop == 'track':\n",
    "                print(\"- Tracks:\")\n",
    "                for album in props[prop]:\n",
    "                    print(f'  - {album[\"properties\"][\"name\"]}')\n",
    "            \n",
    "            else:\n",
    "                print(f'- {prop}: {props[prop]}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: {'namespace': {'og': 'http://ogp.me/ns#'}, 'properties': [('og:type', 'video.other'), ('og:title', 'Harry Styles'), ('og:description', 'Harry Styles, Holmes Chapel. 16.770.656 vind-ik-leuks · 9.058 personen praten hierover. Official Harry Styles Facebook Page.'), ('og:url', 'https://www.facebook.com/harrystyles'), ('og:image:alt', 'Harry Styles'), ('og:image', 'https://scontent-ams4-1.xx.fbcdn.net/v/t39.30808-1/282562961_560018528829158_205099524906925756_n.jpg?stp=dst-jpg_p720x720&_nc_cat=102&ccb=1-7&_nc_sid=5f2048&_nc_ohc=yYLs__r3ZsEAX8JLnOK&_nc_ht=scontent-ams4-1.xx&oh=00_AfBq6kwQhtUL2VXrQsY_vD5AugkzGLGrykZdxKZBe17n0g&oe=6550C1E8'), ('og:locale', 'en_US')]}\n",
      "namespace: {'og': 'http://ogp.me/ns#'}\n",
      "Properties: \n",
      "- og:type: video.other\n",
      "- og:title: Harry Styles\n",
      "- og:description: Harry Styles, Holmes Chapel. 16.770.656 vind-ik-leuks · 9.058 personen praten hierover. Official Harry Styles Facebook Page.\n",
      "- og:url: https://www.facebook.com/harrystyles\n",
      "- og:image:alt: Harry Styles\n",
      "- og:image: https://scontent-ams4-1.xx.fbcdn.net/v/t39.30808-1/282562961_560018528829158_205099524906925756_n.jpg?stp=dst-jpg_p720x720&_nc_cat=102&ccb=1-7&_nc_sid=5f2048&_nc_ohc=yYLs__r3ZsEAX8JLnOK&_nc_ht=scontent-ams4-1.xx&oh=00_AfBq6kwQhtUL2VXrQsY_vD5AugkzGLGrykZdxKZBe17n0g&oe=6550C1E8\n",
      "- og:locale: en_US\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import extruct\n",
    "\n",
    "FB_URL = \"https://www.facebook.com/harrystyles\"\n",
    "req_fb = requests.get(FB_URL, headers={'User-Agent' : \"Social Web Course Student\"})\n",
    "metadata_fb = extruct.extract(htmlstring_or_tree=req_fb.text)\n",
    "\n",
    "#Go through all the items\n",
    "for item_fb in metadata_fb[\"opengraph\"]:\n",
    "    print(\"Raw:\", item_fb)\n",
    "    for props in item_fb:\n",
    "        if props == 'properties':\n",
    "            print(\"Properties: \")\n",
    "            for prop in item_fb[props]:\n",
    "                print(f'- {prop[0]}: {prop[1]}')\n",
    "        else:\n",
    "            print(f'{props}: {item_fb[props]}')\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nocs4YDPeMKB"
   },
   "source": [
    "### Task 3.2\n",
    "Explore the various microformats at http://microformats.org/ and compare the output of the exercises with the output of http://microformats.org/. Think about possible microformats you want to support in your final assignment and read up on how to parse them."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hands-on_2_microformats.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
